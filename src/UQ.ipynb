{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a322ecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/people/d3x771/.conda/envs/LLM/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Unknown option: -C\n",
      "usage: git [--version] [--help] [-c name=value]\n",
      "           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n",
      "           [-p|--paginate|--no-pager] [--no-replace-objects] [--bare]\n",
      "           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n",
      "           <command> [<args>]\n",
      "WARNING:root:No seed has been set in modelcheckpoint or OCPCalculator! Results may not be reproducible on re-run\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run inference on a given lmdb dataset.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from ocpmodels.datasets.lmdb_dataset import LmdbDataset\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader.data_list_loader import DataListLoader\n",
    "\n",
    "sys.path.append(\"/people/d3x771/projects/chemreasoner/chemreasoner/src\")\n",
    "\n",
    "from nnp.oc import OCAdsorptionCalculator\n",
    "\n",
    "ads_calc = OCAdsorptionCalculator(\n",
    "    **{\n",
    "        \"model\": \"gemnet-t\",\n",
    "        \"traj_dir\": Path(\"irrelevant\"),\n",
    "        \"batch_size\": 40,\n",
    "        \"device\": \"cpu\",\n",
    "        \"ads_tag\": 2,\n",
    "        \"fmax\": 0.05,\n",
    "        \"steps\": 300,\n",
    "    }\n",
    ")\n",
    "\n",
    "#{\n",
    "#        \"model\": \"gemnet-oc-22\",\n",
    "#        \"traj_dir\": data_path,\n",
    "#        \"batch_size\": 32,\n",
    "#        \"device\": \"cuda\",\n",
    "#        \"ads_tag\": 2,\n",
    "#        \"fmax\": 0.03,\n",
    "#        \"steps\": 200,\n",
    "#    }\n",
    "\n",
    "torch_calc = ads_calc.get_torch_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a544a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#module load cuda/11.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36e6042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#print(torch_calc.model)\n",
    "print(torch_calc.model.num_blocks)\n",
    "print(torch_calc.model.regress_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a8b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question1: Map each sample GNN input to creating the descriptors per sample\n",
    "# Question2: how do we get descriptor per sample\n",
    "# Question 3: how do we implement initial ranking based on descriptors\n",
    "# Question 4: Can Henry generate other configuration (cell shift, miller index) descriptors that are going into LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad9908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_sample_embeddings(output_embeddings, batch):\n",
    "    \"\"\"\n",
    "    Given a dictionary comtaining model output per batch of the form:\n",
    "    {\"energy\": E_t, \"hidden_h\":h, \"hidden_m\":m, 'edge_index':edge_index}\n",
    "    \n",
    "    generate, embeddings per model input:\n",
    "    [embeddings_atomistic_graph1, embeddings_atomistic_graph2.....embeddings_atomistic_graphN]\n",
    "\n",
    "    \"\"\"\n",
    "    data = output_embeddings\n",
    "    #print(data)\n",
    "    atom_emb = data['hidden_h']\n",
    "    edge_emb = data['hidden_m']\n",
    "    energies = data['energy']\n",
    "    forces = data['forces']\n",
    "    edge_index = data['edge_index']\n",
    "    graph_embs = []\n",
    "    for i in range(len(batch.ptr)-1):\n",
    "        idx_start = batch.ptr[i]\n",
    "        idx_end = batch.ptr[i+1]\n",
    "        #print(i, idx_start, idx_end)\n",
    "        graph_emb = atom_emb[idx_start:idx_end]\n",
    "        #print(graph_emb.size())\n",
    "        graph_emb = torch.mean(graph_emb, 0)\n",
    "        #print(graph_emb.size())\n",
    "        graph_embs.append(graph_emb)\n",
    "    return(np.array(graph_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58782797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, List, Optional\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url, extract_tar\n",
    "import numpy as np\n",
    "import lzma\n",
    "import ase\n",
    "from ase.io import iread\n",
    "from ase.db import connect\n",
    "from activate import data\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8dd2331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    data format\\n    z -> atomic numbers\\n    y -> prediction target/ total energy (optional here)\\n    pos -> coordinates of all atoms\\n    f -> forces per atom\\n    cell -> periodic boundary conditions for calculating neiborhood calculations\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    data format\n",
    "    z -> atomic numbers\n",
    "    y -> prediction target/ total energy (optional here)\n",
    "    pos -> coordinates of all atoms\n",
    "    f -> forces per atom\n",
    "    cell -> periodic boundary conditions for calculating neiborhood calculations\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f43bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 256\n",
      "DataBatch(y=[256], pos=[18887, 3], z=[18887], f=[18887, 3], cell=[256, 3, 3], e_total=[256], e_ref=[256], rcell=[768, 3], name=[256], system_id=[256], idx=[256], natoms=[256], pbc=[768], batch=[18887], ptr=[257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0:   0%|                                                                                     | 0/1 [00:00<?, ?it/s]/people/d3x771/.conda/envs/LLM/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/models/gemnet/gemnet.py:373: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  neighbors_new // 2,\n",
      "/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/models/gemnet/gemnet.py:471: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  block_sizes = neighbors // 2\n",
      "device 0:   0%|                                                                                     | 0/1 [03:58<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 256\n",
      "DataBatch(y=[256], pos=[19108, 3], z=[19108], f=[19108, 3], cell=[256, 3, 3], e_total=[256], e_ref=[256], rcell=[768, 3], name=[256], system_id=[256], idx=[256], natoms=[256], pbc=[768], batch=[19108], ptr=[257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0:   0%|                                                                                     | 0/1 [04:14<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 256\n",
      "DataBatch(y=[256], pos=[19478, 3], z=[19478], f=[19478, 3], cell=[256, 3, 3], e_total=[256], e_ref=[256], rcell=[768, 3], name=[256], system_id=[256], idx=[256], natoms=[256], pbc=[768], batch=[19478], ptr=[257])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "device 0:   0%|                                                                                     | 0/1 [02:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     31\u001b[0m     batch\u001b[38;5;241m.\u001b[39matomic_numbers \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mz\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_calc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mper_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m batch_embeddings \u001b[38;5;241m=\u001b[39m get_per_sample_embeddings(torch_calc\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_outemb, batch)\n\u001b[1;32m     34\u001b[0m batch_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/LLM/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/trainers/ocp_trainer.py:458\u001b[0m, in \u001b[0;36mOCPTrainer.predict\u001b[0;34m(self, data_loader, per_image, results_file, disable_tqdm)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28menumerate\u001b[39m(data_loader),\n\u001b[1;32m    451\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable_tqdm,\n\u001b[1;32m    455\u001b[0m ):\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 458\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m target_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    461\u001b[0m         pred \u001b[38;5;241m=\u001b[39m out[target_key]\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/trainers/ocp_trainer.py:252\u001b[0m, in \u001b[0;36mOCPTrainer._forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m--> 252\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m### TODO: Move into BaseModel in OCP 2.0\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.conda/envs/LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/common/utils.py:139\u001b[0m, in \u001b[0;36mconditional_grad.<locals>.decorator.<locals>.cls_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregress_forces \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirect_forces\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    138\u001b[0m     f \u001b[38;5;241m=\u001b[39m dec(func)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/models/gemnet/gemnet.py:542\u001b[0m, in \u001b[0;36mGemNetT.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# (nAtoms, num_targets), (nEdges, num_targets)\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_blocks):\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# Interaction block\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     h, m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrbf3\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrbf3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcbf3\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbf3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid3_ragged_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid3_ragged_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid_swap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_swap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid3_ba\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid3_ba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid3_ca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid3_ca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrbf_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrbf_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (nAtoms, emb_size_atom), (nEdges, emb_size_edge)\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     E, F \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_blocks[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m](h, m, rbf_out, idx_t)\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# (nAtoms, num_targets), (nEdges, num_targets)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/models/gemnet/layers/interaction_block.py:168\u001b[0m, in \u001b[0;36mInteractionBlockTripletsOnly.forward\u001b[0;34m(self, h, m, rbf3, cbf3, id3_ragged_idx, id_swap, id3_ba, id3_ca, rbf_h, idx_s, idx_t)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Initial transformation\u001b[39;00m\n\u001b[1;32m    166\u001b[0m x_ca_skip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_ca(m)  \u001b[38;5;66;03m# (nEdges, emb_size_edge)\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrip_interaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrbf3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcbf3\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid3_ragged_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_swap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid3_ba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid3_ca\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m## ----------------------------- Merge Embeddings after Triplet Interaction ------------------------------ ##\u001b[39;00m\n\u001b[1;32m    179\u001b[0m x \u001b[38;5;241m=\u001b[39m x_ca_skip \u001b[38;5;241m+\u001b[39m x3  \u001b[38;5;66;03m# (nEdges, emb_size_edge)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/models/gemnet/layers/interaction_block.py:326\u001b[0m, in \u001b[0;36mTripletInteraction.forward\u001b[0;34m(self, m, rbf3, cbf3, id3_ragged_idx, id_swap, id3_ba, id3_ca)\u001b[0m\n\u001b[1;32m    323\u001b[0m x_ba \u001b[38;5;241m=\u001b[39m x_ba[id3_ba]\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Efficient bilinear layer\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_cbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbf3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid3_ca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid3_ragged_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# (nEdges, emb_size_quad)\u001b[39;00m\n\u001b[1;32m    328\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_cbf_sum(x, ref\u001b[38;5;241m=\u001b[39mx_ba)\n",
      "File \u001b[0;32m~/.conda/envs/LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/qfs/people/d3x771/projects/chemreasoner/chemreasoner/ext/ocp/ocpmodels/models/gemnet/layers/efficient.py:168\u001b[0m, in \u001b[0;36mEfficientInteractionBilinear.forward\u001b[0;34m(self, basis, m, id_reduce, id_ragged_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m rbf_W1_sum_k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(rbf_W1, sum_k)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# (nEdges, emb_size_interm, emb_size)\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Bilinear: Sum over emb_size_interm and emb_size\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m m_ca \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrbf_W1_sum_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# (emb_size, nEdges, units_out)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m m_ca \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(m_ca, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import oc20\n",
    "\n",
    "dataset='OC20'\n",
    "\n",
    "\n",
    "if(dataset == 'lmdb'):\n",
    "    lmdb_dir='/qfs/projects/chemreasoner/test_lmdb/'\n",
    "    dataset = LmdbDataset({\"src\": lmdb_dir})\n",
    "    loader = DataListLoader(dataset, batch_size=20, shuffle=False)\n",
    "elif(dataset == 'OC20'):\n",
    "    datadir= '/qfs/projects/chemreasoner/data/OC20/'\n",
    "    dataset = oc20.OC20(datadir, tag='200k')\n",
    "    loader = DataListLoader(dataset, batch_size=256, shuffle=False)\n",
    "else:\n",
    "    print(\"UNSUPPORTED DATASET FORMAT, exiting...\")\n",
    "    sys.exit(1)\n",
    "\n",
    "X = []\n",
    "Y= []\n",
    "for i, data_list in enumerate(loader):\n",
    "    \n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    \n",
    "    print(i, len(batch))\n",
    "    print(batch)\n",
    "    #print(batch.ptr)\n",
    "    if dataset =='lmdb':\n",
    "        print(batch.descriptor)\n",
    "    elif(dataset == 'OC20'):\n",
    "        print(batch.name)\n",
    "        batch.atomic_numbers = batch.z\n",
    "    outputs = torch_calc.predict(batch,per_image=False)\n",
    "    batch_embeddings = get_per_sample_embeddings(torch_calc.model.model_outemb, batch)\n",
    "    batch_output = outputs['energy']\n",
    "    #print(batch_embeddings.shap,batch_output.shape)\n",
    "    for emb, out in zip(batch_embeddings, batch_output):\n",
    "        X.append(emb)\n",
    "        Y.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "060bc63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512) (512, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(X)\n",
    "Y= np.array(Y)\n",
    "print(X.shape, Y.shape)\n",
    "#X = np.reshape(X, (512, 512))\n",
    "#Y = np.reshape(Y, (512, 1))\n",
    "#print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3e0216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import xgboost as xgb\n",
    " \n",
    "class GBMRegressor:\n",
    "    \"\"\"\n",
    "    Union approach for Gradient Boosting Machine uncertainty estimation\n",
    "    from https://link.springer.com/article/10.1186/s13321-023-00753-5 \n",
    "    \"\"\"\n",
    "    def __init__(self, savedir='./', lower_alpha=0.1, upper_alpha=0.9, n_estimators=100):\n",
    "        \"\"\"Initialize GBM regressors\n",
    "        Args:\n",
    "          savedir (str): Directory to save fit GBM regressors. \n",
    "                         (default: :obj:`./`)\n",
    "          lower_alpha (float): The alpha-quantile of the quantile loss function.\n",
    "                               Values must be in the range (0.0, 1.0). \n",
    "                               (default: :obj:`0.1`)\n",
    "          upper_alpha (float): The alpha-quantile of the quantile loss function. \n",
    "                               Values must be in the range (0.0, 1.0). \n",
    "                               (default: :obj:`0.9`)\n",
    "          n_estimators (int): The number of boosting stages to perform.\n",
    "                              (default: :obj:`100`)\n",
    "        \"\"\"\n",
    "        self.savedir = savedir\n",
    "        self.alpha = np.array([lower_alpha, upper_alpha])\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "    @property\n",
    "    def model_file(self):\n",
    "        return 'GBMRegressor.pkl'\n",
    " \n",
    "        \n",
    "    def update(self, embeddings, target):\n",
    "        \"\"\"Update GBM models after training epoch.\"\"\"          \n",
    "        Xy = xgb.QuantileDMatrix(embeddings, target)\n",
    "        Xy_test = xgb.QuantileDMatrix(embeddings, target, ref=Xy)\n",
    "\n",
    "        self.booster = xgb.train(\n",
    "            {\n",
    "                \"objective\": \"reg:quantileerror\",\n",
    "                \"tree_method\": \"hist\",\n",
    "                \"quantile_alpha\": self.alpha,\n",
    "                \"learning_rate\": 0.04,\n",
    "                \"max_depth\": 5,\n",
    "                \"verbosity\": 0,\n",
    "                \"disable_default_eval_metric\": True,\n",
    "            },\n",
    "            Xy,\n",
    "            num_boost_round=self.n_estimators,\n",
    "            )\n",
    " \n",
    "    def predict(self, embeddings):\n",
    "        \"\"\"Predict uncertainties for set of embeddings.\"\"\"\n",
    " \n",
    "        scores = self.booster.inplace_predict(embeddings).T\n",
    "        return np.abs(scores[0]-scores[1])/2\n",
    " \n",
    "    def _save(self):\n",
    "        \"\"\"Save GBM regressor parameters to file.\"\"\"\n",
    "        with open(os.path.join(self.savedir, self.model_file), 'wb') as f:\n",
    "            pickle.dump(self.booster, f)\n",
    " \n",
    " \n",
    "    def _load(self):\n",
    "        \"\"\"Load trained GBM regressors from file.\"\"\"\n",
    "        if os.path.isfile(os.path.join(self.savedir, self.model_file)):\n",
    "            with open(os.path.join(self.savedir, self.model_file), 'rb') as f:\n",
    "                self.booster = pickle.load(f)\n",
    "        else:\n",
    "            logging.warning(f'No trained GBM regressor found in {self.savedir}. Call GBMRegressor.update to train a model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c319b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install xgboost\n",
    "uq_model = GBMRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb097d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, Y , test_size=0.3, random_state=42)\n",
    "\n",
    "uq_model.update(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978cb689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6033977 , 0.73653156, 1.6619005 , 1.220981  , 0.9422441 ,\n",
       "       1.1381476 , 0.65301645, 0.5406874 , 0.78450614, 1.2528241 ,\n",
       "       1.248014  , 0.6767561 , 1.2372406 , 0.77329195, 1.3526403 ,\n",
       "       0.9138219 , 0.84102476, 1.4724238 , 1.1552675 , 1.1156557 ,\n",
       "       2.0222178 , 1.0507889 , 1.2224222 , 6.7936234 , 1.9063494 ,\n",
       "       0.9781883 , 1.9560361 , 3.1249433 , 0.9493817 , 1.0077488 ,\n",
       "       0.9555403 , 0.85769784, 1.2346307 , 0.6665735 , 1.753107  ,\n",
       "       0.7544469 , 1.4823492 , 1.0629822 , 1.1034492 , 0.80066186,\n",
       "       1.757617  , 2.3911357 , 0.35435978, 1.2724328 , 1.222982  ,\n",
       "       1.237083  , 0.7011486 , 0.97969615, 0.29001102, 0.93491465,\n",
       "       0.5383747 , 1.631411  , 0.84849364, 1.4128246 , 0.60093904,\n",
       "       0.8664035 , 0.42883253, 0.75119936, 1.0361155 , 1.1000831 ,\n",
       "       0.51049984, 0.81972146, 2.64171   , 0.81146026, 2.646253  ,\n",
       "       0.6346876 , 0.6521261 , 0.7723559 , 1.5382522 , 1.277319  ,\n",
       "       1.9854906 , 1.0271649 , 1.1764631 , 1.5450937 , 1.0242124 ,\n",
       "       0.91633403, 2.4877458 , 1.4776808 , 1.7179296 , 1.0547862 ,\n",
       "       0.6055541 , 1.001134  , 0.35149541, 1.2400858 , 5.2796216 ,\n",
       "       1.719404  , 1.0175087 , 1.6245348 , 1.3679123 , 0.89608854,\n",
       "       0.8594429 , 1.784961  , 1.2191995 , 1.014785  , 0.4849948 ,\n",
       "       0.72853446, 3.177858  , 0.42485294, 0.96718276, 1.0698963 ,\n",
       "       1.0816638 , 1.4075406 , 0.9362321 , 2.643777  , 1.8570279 ,\n",
       "       1.1826952 , 1.5518565 , 1.5885289 , 1.8026855 , 0.87596416,\n",
       "       0.77572155, 0.82963514, 1.1179754 , 0.8602216 , 1.3814375 ,\n",
       "       0.35852745, 1.69567   , 0.69343185, 1.8747096 , 1.3641638 ,\n",
       "       1.1484032 , 1.0990957 , 1.2996053 , 4.595989  , 0.3632909 ,\n",
       "       1.5604522 , 0.8857837 , 1.6546513 , 0.55367273, 0.7459736 ,\n",
       "       3.025783  , 0.7200122 , 1.597874  , 1.5273545 , 1.2588947 ,\n",
       "       0.7795285 , 0.8239658 , 1.7693286 , 5.847119  , 0.8841912 ,\n",
       "       1.3895884 , 0.36868212, 2.3592257 , 3.5816748 , 0.6847216 ,\n",
       "       0.80540967, 0.6212216 , 1.058934  , 0.55391306, 0.80510044,\n",
       "       2.226212  , 2.1759512 , 0.7253876 , 0.5777534 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uq_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2574a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot X descriptors against the adsorption energy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
